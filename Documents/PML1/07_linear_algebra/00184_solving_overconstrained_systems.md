# 선형 연립방정식 과대제약 체계 풀기 (최소 제곱 추정)

**선형 연립방정식 과대제약 체계**는 방정식의 수가 미지수의 수보다 많아, 모든 방정식을 동시에 만족시키는 해가 존재하지 않는 경우를 의미합니다. 이러한 경우, **최소 제곱 추정(Least Squares Estimation)**은 모든 방정식의 오차를 최소화하는 해를 찾는 방법입니다.

## 과대제약 선형 연립방정식의 정의

과대제약 선형 연립방정식은 다음과 같은 형태로 표현됩니다:

$$
Ax = b
$$

여기서,
- $A$는 $m \times n$ 크기의 계수 행렬로, $m > n$인 경우 과대제약 체계입니다.
- $x$는 $n \times 1$ 크기의 미지수 벡터입니다.
- $b$는 $m \times 1$ 크기의 상수 벡터입니다.

이 시스템에서는 $Ax = b$를 정확히 만족시키는 해를 찾는 것이 불가능할 수 있으며, 따라서 잔차(residual) $\|Ax - b\|_2$를 최소화하는 해를 구하는 것이 목표가 됩니다.

## 최소 제곱 추정의 정의

최소 제곱 추정은 다음과 같이 정의됩니다:

$$
x_{\text{LS}} = \text{argmin}_x \|Ax - b\|_2^2
$$

이는 잔차의 제곱합을 최소화하는 $x$를 찾는 문제로, 잔차란 $Ax$와 $b$ 간의 차이입니다.

## 최소 제곱 해를 구하는 방법

### 1. 정규 방정식 (Normal Equation)

최소 제곱 해를 구하는 가장 기본적인 방법은 **정규 방정식(Normal Equation)**을 푸는 것입니다. 정규 방정식은 다음과 같이 주어집니다:

$$
A^T A x = A^T b
$$

이 식을 풀어 $x_{\text{LS}}$를 구할 수 있습니다:

$$
x_{\text{LS}} = (A^T A)^{-1} A^T b
$$

이 방법은 간단하지만, $A^T A$의 역행렬을 계산해야 하므로 $A^T A$가 특이행렬(singular matrix)이거나 수치적으로 불안정한 경우 문제가 발생할 수 있습니다.

### 2. SVD(특이값 분해) 사용

특이값 분해(Singular Value Decomposition, SVD)를 사용하여 최소 제곱 해를 구할 수 있습니다. $A$의 SVD는 다음과 같이 표현됩니다:

$$
A = U \Sigma V^T
$$

여기서,
- $U$는 $m \times m$ 크기의 직교 행렬,
- $\Sigma$는 $m \times n$ 크기의 대각 행렬로, $A$의 특이값들이 대각선에 배치됩니다.
- $V$는 $n \times n$ 크기의 직교 행렬입니다.

SVD를 사용하면 최소 제곱 해는 다음과 같이 구할 수 있습니다:

$$
x_{\text{LS}} = V \Sigma^+ U^T b
$$

여기서 $\Sigma^+$는 $\Sigma$의 유사역행렬입니다. SVD는 정규 방정식보다 수치적으로 더 안정적이며, 특히 $A^T A$가 조건수가 큰 경우에도 유리합니다.

### 3. QR 분해를 이용한 방법

QR 분해를 사용하여 최소 제곱 해를 구할 수 있습니다. QR 분해는 $A$를 직교 행렬 $Q$와 상삼각 행렬 $R$로 분해하는 방법입니다:

$$
A = QR
$$

여기서 $Q$는 $m \times n$ 크기의 직교 행렬이고, $R$은 $n \times n$ 크기의 상삼각 행렬입니다. 이 경우 최소 제곱 해는 다음과 같이 구해집니다:

$$
x_{\text{LS}} = R^{-1} Q^T b
$$

QR 분해는 특히 대규모 문제에서 효율적으로 최소 제곱 해를 계산하는 데 사용됩니다.

## 최소 제곱 추정의 응용

최소 제곱 추정은 다양한 실제 문제에서 중요한 역할을 합니다. 그 중 일부는 다음과 같습니다:

### 1. 회귀 분석

회귀 분석에서는 독립 변수와 종속 변수 간의 관계를 모델링할 때 최소 제곱 추정을 사용하여 회귀 계수를 추정합니다.

### 2. 신호 처리

신호 복원 및 잡음 제거에서 최소 제곱 추정이 사용됩니다. 특히, 이상치(outlier)에 대한 민감도가 낮아, 데이터의 일반적인 경향을 파악하는 데 유리합니다.

### 3. 기계 학습

기계 학습에서 최소 제곱 추정은 선형 회귀 모델의 학습에 널리 사용되며, 데이터와 모델 간의 차이를 최소화하는 데 사용됩니다.

## 최소 제곱 추정의 장점과 한계

- **장점**: 최소 제곱 추정은 계산이 상대적으로 간단하고, 대부분의 경우에서 안정적이며, 다양한 응용 분야에서 효과적으로 사용될 수 있습니다.
- **한계**: 데이터에 이상치가 있는 경우 민감하게 반응할 수 있으며, 이러한 경우에는 로버스트 회귀(robust regression) 등의 대체 방법이 필요할 수 있습니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

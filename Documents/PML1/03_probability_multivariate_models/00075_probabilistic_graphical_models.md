# 확률적 그래프 모델 (Probabilistic Graphical Models)

**확률적 그래프 모델**(Probabilistic Graphical Models, PGM)은 확률 변수들 사이의 의존성을 그래프로 표현한 모델입니다. 그래프는 **노드**(확률 변수)와 **엣지**(의존 관계)로 구성되며, 이를 통해 고차원 데이터에서 복잡한 확률 관계를 간단하고 직관적으로 표현할 수 있습니다. PGM은 두 가지 주요 유형인 **베이지안 네트워크**(Bayesian Networks)와 **마르코프 랜덤 필드**(Markov Random Fields)로 나뉩니다.

## 1. 확률적 그래프 모델의 구성 요소

PGM은 크게 두 가지 요소로 구성됩니다:
1. **그래프 구조**: 변수들 간의 의존성 관계를 나타내는 그래프.
2. **확률 분포**: 변수들의 결합 확률 분포를 나타내며, 그래프 구조에 의해 조건부 독립성을 표현할 수 있습니다.

### 1.1. 그래프의 종류
- **유향 그래프 (Directed Graph)**: 그래프의 엣지가 방향을 가지며, 베이지안 네트워크(Bayesian Network)를 형성합니다.
- **무향 그래프 (Undirected Graph)**: 엣지가 방향을 가지지 않으며, 마르코프 랜덤 필드(Markov Random Field)를 형성합니다.

### 1.2. 조건부 독립성
확률적 그래프 모델은 변수들 간의 조건부 독립성을 그래프 구조로 명확하게 나타낼 수 있습니다. 예를 들어, 유향 그래프에서 한 노드의 부모 노드가 주어졌을 때, 해당 노드는 부모 노드를 제외한 다른 모든 노드와 조건부 독립성을 가집니다.

## 2. 베이지안 네트워크 (Bayesian Networks)

**베이지안 네트워크**는 확률 변수가 유향 비순환 그래프(Directed Acyclic Graph, DAG)로 표현된 모델입니다. 각 변수는 부모 변수가 주어졌을 때 조건부 독립성을 갖습니다.

### 2.1. 조건부 분포

베이지안 네트워크의 결합 확률 분포는 각 변수의 조건부 분포의 곱으로 표현됩니다. $X = \{X_1, X_2, \dots, X_N\}$라는 변수가 있을 때, 결합 확률 분포는 다음과 같이 계산됩니다:

$$
p(X) = \prod_{i=1}^{N} p(X_i \mid \text{Pa}(X_i))
$$

여기서 $\text{Pa}(X_i)$는 변수 $X_i$의 부모 노드를 의미합니다.

### 2.2. 예시

예를 들어, 질병 진단 문제에서 질병(Disease)이 증상(Symptom)을 유발한다고 가정하면, 다음과 같은 그래프 구조를 가질 수 있습니다:

$$
\text{Disease} \rightarrow \text{Symptom}
$$

이 경우, 결합 확률 분포는 다음과 같습니다:

$$
p(\text{Disease}, \text{Symptom}) = p(\text{Disease}) \cdot p(\text{Symptom} \mid \text{Disease})
$$

## 3. 마르코프 랜덤 필드 (Markov Random Fields)

**마르코프 랜덤 필드**(MRF)는 무향 그래프로 표현된 확률 모델로, 인접한 노드들만 서로 의존하는 구조를 가집니다. MRF는 모든 노드들이 서로 상호작용할 수 있지만, 인접하지 않은 노드는 조건부 독립성을 가집니다.

### 3.1. 결합 확률 분포

마르코프 랜덤 필드에서 결합 확률 분포는 **클리크**(clique)라는 완전 연결된 부분 그래프에 대해 정의된 **퍼텐셜 함수**(potential function)를 기반으로 표현됩니다. 클리크 $C$에 대해, 결합 확률 분포는 다음과 같이 주어집니다:

$$
p(X) = \frac{1}{Z} \prod_{C} \psi_C(X_C)
$$

여기서:
- $\psi_C(X_C)$는 클리크 $C$에 대한 퍼텐셜 함수,
- $Z$는 **정규화 상수**(normalization constant)로, 확률 분포가 1이 되도록 조정하는 역할을 합니다.

### 3.2. 조건부 독립성

마르코프 랜덤 필드에서 한 노드는 이웃하지 않은 노드와 조건부 독립성을 갖습니다. 즉, 그래프에서 경로가 끊긴 노드는 서로 독립적인 관계를 유지합니다.

## 4. 학습과 추론

확률적 그래프 모델에서 주요 과제는 **매개변수 학습**과 **추론**입니다. 학습은 모델의 파라미터(예: 조건부 확률)를 추정하는 과정이며, 추론은 주어진 데이터에 기반해 숨겨진 변수를 예측하는 과정입니다.

### 4.1. 학습 (Learning)

- **매개변수 학습**: 주어진 데이터를 바탕으로 모델의 매개변수를 추정합니다. 완전한 데이터가 주어지면 최대 우도 추정(Maximum Likelihood Estimation, MLE)을 사용할 수 있습니다.
- **구조 학습**: 그래프의 구조를 추정하는 문제로, 주어진 데이터에서 변수들 간의 의존 관계를 학습합니다.

### 4.2. 추론 (Inference)

추론은 모델이 주어진 관측된 데이터를 바탕으로 숨겨진 변수를 예측하는 과정입니다. 주요 추론 방법으로는 **정확한 추론**과 **근사 추론**이 있습니다:
- **정확한 추론**: 메시지 전달 알고리즘(Belief Propagation)을 통해 가능하며, 그래프의 구조가 단순할 경우 효과적입니다.
- **근사 추론**: 복잡한 그래프 구조에서는 정확한 추론이 어렵기 때문에 MCMC(Markov Chain Monte Carlo) 또는 변분 추론(Variational Inference) 등의 방법을 사용합니다.

## 5. 확률적 그래프 모델의 응용

PGM은 다음과 같은 다양한 분야에서 활용됩니다:
- **자연어 처리**: 단어 간의 관계를 모델링하고 문장 구조를 이해하는 데 사용됩니다.
- **컴퓨터 비전**: 이미지에서 객체 간의 관계를 모델링하여 객체 인식이나 분할에 사용됩니다.
- **의료 분야**: 질병 진단과 같은 문제에서 환자의 증상과 질병 간의 관계를 모델링하는 데 사용됩니다.

## 6. 확률적 그래프 모델의 장점과 한계

### 6.1. 장점
- 복잡한 의존 관계를 시각적으로 표현할 수 있어 직관적인 이해가 가능합니다.
- 조건부 독립성을 명확하게 나타내므로 고차원 데이터에서 계산 효율성을 높일 수 있습니다.

### 6.2. 한계
- 그래프 구조를 수동으로 정의해야 하는 경우, 적절한 구조를 설정하기 어렵습니다.
- 큰 규모의 그래프에서는 추론 과정이 매우 복잡해질 수 있습니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

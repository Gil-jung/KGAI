# 마할라노비스 거리 (Mahalanobis Distance)

**마할라노비스 거리(Mahalanobis Distance)**는 1936년 인도 통계학자 프라샨타 찬드라 마할라노비스(Prasanta Chandra Mahalanobis)가 제안한 거리 측정 방법으로, 데이터 간의 거리를 계산할 때 데이터의 분포를 고려하는 방식입니다. 이는 특히 다변량 데이터에서 데이터 간의 차이를 정량화할 때 유용합니다.

## 1. 마할라노비스 거리의 정의

마할라노비스 거리는 두 벡터 간의 거리를 측정하는 방법으로, 데이터의 공분산을 고려하여 유클리드 거리(Euclidean Distance)와는 달리 각 변수 간의 상관성을 반영합니다. 이 거리는 다음과 같이 정의됩니다:

$$
D_M(\mathbf{x}) = \sqrt{(\mathbf{x} - \boldsymbol{\mu})^T \mathbf{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu})}
$$

여기서:

- $\mathbf{x}$: 관측된 데이터 벡터
- $\boldsymbol{\mu}$: 데이터의 평균 벡터
- $\mathbf{\Sigma}$: 데이터의 공분산 행렬
- $\mathbf{\Sigma}^{-1}$: 공분산 행렬의 역행렬

이 식에서 알 수 있듯이, 마할라노비스 거리는 단순히 두 점 사이의 거리가 아니라, 데이터의 분포를 고려하여 측정됩니다.

## 2. 마할라노비스 거리의 특징

### 2.1 데이터의 분포 반영

마할라노비스 거리는 데이터의 분포를 고려하기 때문에, 각 변수 간의 상관성을 반영합니다. 이는 데이터가 비등방적(즉, 변수 간의 분포가 동일하지 않은 경우)일 때 매우 유용합니다.

### 2.2 무차원 거리

마할라노비스 거리는 단위가 없는 무차원 거리입니다. 이는 다른 단위를 가진 변수들 간의 거리를 직접 비교할 수 있게 해주며, 이로 인해 여러 변수 간의 균형 있는 비교가 가능합니다.

### 2.3 이변량 정규 분포에서의 해석

이변량 정규 분포에서 마할라노비스 거리는 각 데이터 포인트가 평균으로부터 떨어진 정도를 측정하는데, 이 거리는 $\chi^2$ 분포를 따릅니다. 따라서 마할라노비스 거리를 사용하면 특정 데이터 포인트가 전체 데이터 집합의 평균에서 얼마나 벗어나 있는지를 통계적으로 해석할 수 있습니다.

## 3. 마할라노비스 거리의 응용

마할라노비스 거리는 다양한 응용 분야에서 사용됩니다:

- **이상치 탐지(Outlier Detection)**: 데이터 분포에서 멀리 떨어진 점들을 이상치로 식별하는 데 사용됩니다.
- **클러스터링(Clustering)**: 군집 분석에서 데이터 포인트 간의 거리를 계산하여 유사한 포인트들을 묶는 데 사용됩니다.
- **분류(Classification)**: 다변량 분포에서 새로운 데이터 포인트가 어느 클래스에 속하는지 결정하는 데 유용합니다.
- **패턴 인식(Pattern Recognition)**: 얼굴 인식과 같은 응용 분야에서, 패턴 간의 거리를 측정하여 특정 클래스나 카테고리에 속하는지를 판단합니다.

## 4. 마할라노비스 거리 계산의 예

예를 들어, 데이터 벡터 $\mathbf{x} = [x_1, x_2]^T$와 평균 벡터 $\boldsymbol{\mu} = [\mu_1, \mu_2]^T$가 주어졌다고 가정합시다. 또한 공분산 행렬이 다음과 같다고 하겠습니다:

$$
\mathbf{\Sigma} =
\begin{pmatrix}
\sigma_{11} & \sigma_{12} \\
\sigma_{21} & \sigma_{22}
\end{pmatrix}
$$

이때, 마할라노비스 거리는 다음과 같이 계산됩니다:

$$
D_M(\mathbf{x}) = \sqrt{
\begin{pmatrix}
x_1 - \mu_1 \\
x_2 - \mu_2
\end{pmatrix}^T
\mathbf{\Sigma}^{-1}
\begin{pmatrix}
x_1 - \mu_1 \\
x_2 - \mu_2
\end{pmatrix}
}
$$

이를 통해 데이터 포인트 $\mathbf{x}$가 평균 벡터 $\boldsymbol{\mu}$로부터 얼마나 떨어져 있는지를 공분산을 고려하여 계산할 수 있습니다.

## 5. 마할라노비스 거리와 유클리드 거리의 비교

마할라노비스 거리와 유클리드 거리의 주요 차이점은 다음과 같습니다:

- **유클리드 거리**는 변수 간의 상관성을 고려하지 않고 단순히 좌표 공간에서의 직선 거리를 측정합니다.
- **마할라노비스 거리**는 데이터의 분포를 반영하여 거리 측정 시 변수 간의 상관성을 고려합니다. 이는 동일한 거리 값을 가지는 경우에도 마할라노비스 거리가 더 정확한 측정을 제공할 수 있음을 의미합니다.

## 6. 결론

마할라노비스 거리는 데이터 간의 거리를 측정하는 데 있어 매우 유용한 방법으로, 특히 다변량 데이터에서 그 진가를 발휘합니다. 데이터의 분포를 반영하여 변수 간의 상관성을 고려할 수 있기 때문에, 다양한 통계 분석 및 머신러닝 분야에서 폭넓게 활용되고 있습니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

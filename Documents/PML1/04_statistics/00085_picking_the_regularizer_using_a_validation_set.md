# 검증 집합을 사용해 정칙자 고르기

모델 학습 시 **정칙화(Regularization)**는 과적합(Overfitting)을 방지하고 일반화 성능을 높이는 데 중요한 역할을 합니다. 하지만 정칙화의 효과는 **정칙화 강도**에 크게 의존하며, 이 강도는 정칙화 항에 곱해지는 **정칙자(Regularization Parameter)** $\lambda$로 조절됩니다. 적절한 정칙자를 선택하는 과정은 모델의 성능에 중요한 영향을 미치며, 이를 위해 **검증 집합(Validation Set)**을 사용하는 것이 일반적입니다.

## 1. 정칙자의 역할

정칙자 $\lambda$는 모델의 손실 함수에 추가되는 정칙화 항의 가중치를 조절합니다. 이 값이 크면 모델의 복잡도가 강하게 억제되어 과소적합(Underfitting)이 발생할 수 있으며, 반대로 너무 작으면 과적합이 발생할 수 있습니다. 따라서 $\lambda$의 적절한 값을 선택하는 것이 중요합니다.

정칙화된 손실 함수는 다음과 같이 정의됩니다:

$$
J(\theta) = L(\theta) + \lambda \cdot R(\theta)
$$

여기서:
- $J(\theta)$: 정칙화된 손실 함수
- $L(\theta)$: 원래의 손실 함수
- $\lambda$: 정칙자
- $R(\theta)$: 정칙화 항 (예: L2 정칙화에서는 $\sum_{i=1}^{n} \theta_i^2$)

## 2. 검증 집합을 통한 정칙자 선택

검증 집합은 학습 과정에서 모델의 성능을 평가하고 최적의 하이퍼파라미터를 선택하는 데 사용되는 데이터 세트입니다. 이 검증 집합은 학습에 사용되지 않은 데이터로 구성되며, 학습된 모델이 새로운 데이터에 대해 얼마나 잘 일반화되는지를 평가하는 데 도움을 줍니다.

### 절차

1. **데이터 분할**: 주어진 데이터를 학습 집합, 검증 집합, 테스트 집합으로 나눕니다. 여기서 검증 집합은 정칙자 $\lambda$를 선택하기 위한 목적으로 사용됩니다.

2. **모델 학습**: 다양한 $\lambda$ 값을 사용하여 모델을 학습시킵니다. 이때 학습은 학습 집합을 사용하여 이루어집니다.

3. **검증 집합에서 평가**: 학습된 각 모델에 대해 검증 집합에서 성능을 평가합니다. 일반적으로 이때 사용되는 성능 척도는 검증 집합에 대한 손실 함수 값이나 정확도입니다.

4. **최적의 $\lambda$ 선택**: 검증 집합에서 가장 좋은 성능을 보이는 $\lambda$ 값을 선택합니다.

5. **최종 모델 학습**: 선택된 $\lambda$를 사용하여 학습 집합과 검증 집합을 합친 데이터로 모델을 최종 학습합니다.

6. **테스트 집합에서 평가**: 최종 모델의 일반화 성능을 테스트 집합에서 평가합니다.

## 3. 교차 검증 (Cross-Validation)

때로는 검증 집합만으로는 $\lambda$를 안정적으로 선택하기 어려울 수 있습니다. 이러한 경우 **교차 검증** 기법을 사용할 수 있습니다. 교차 검증은 데이터를 여러 개의 부분 집합으로 나누고, 각 부분을 번갈아가며 검증 집합으로 사용하여 여러 번 모델을 학습하고 평가하는 방법입니다.

대표적인 방법으로 **K-겹 교차 검증(K-Fold Cross-Validation)**이 있으며, 이는 데이터를 $K$개의 부분으로 나누어 각 폴드에 대해 모델을 학습하고 검증하는 방법입니다. 이 방법은 검증 집합에 의한 데이터 손실을 최소화할 수 있습니다.

$$
\text{Cross-Validation Error} = \frac{1}{K} \sum_{k=1}^{K} \text{Validation Error on Fold } k
$$

여기서 $K$는 폴드의 수입니다.

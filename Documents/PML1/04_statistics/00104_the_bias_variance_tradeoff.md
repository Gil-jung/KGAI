# 편향-분산 트레이드오프 (Bias-Variance Tradeoff)

## 개요

편향-분산 트레이드오프는 머신러닝 모델의 예측 성능을 이해하고 최적화하는 데 중요한 개념입니다. 이 트레이드오프는 모델의 복잡성과 예측 오류 사이의 관계를 설명하며, 주로 모델이 학습 데이터에 대해 과적합(Overfitting) 또는 과소적합(Underfitting)되는 이유를 분석할 때 사용됩니다.

## 편향(Bias)과 분산(Variance)

### 편향 (Bias)

편향은 모델이 데이터의 실제 패턴을 일반화하지 못하고, 잘못된 가정을 통해 예측하는 경향을 의미합니다. 편향이 높은 모델은 보통 간단한 구조를 가지며, 복잡한 패턴을 잘 학습하지 못해 과소적합의 원인이 됩니다. 이러한 모델은 학습 데이터와 새로운 데이터에 대해 일관되게 큰 오류를 발생시킵니다.

수식적으로, 편향은 다음과 같이 정의됩니다:

$$
\text{Bias}(\hat{f}) = \mathbb{E}[\hat{f}(x)] - f(x)
$$

여기서 \( \hat{f}(x) \)는 모델의 예측 값이고, \( f(x) \)는 데이터의 실제 함수입니다.

### 분산 (Variance)

분산은 모델이 학습 데이터의 작은 변동에 얼마나 민감하게 반응하는지를 나타냅니다. 분산이 높은 모델은 데이터에 매우 민감하게 반응하여, 학습 데이터에는 매우 정확하게 맞출 수 있지만 새로운 데이터에 대해서는 성능이 떨어질 가능성이 큽니다. 이는 과적합의 원인이 됩니다.

분산은 다음과 같이 정의됩니다:

$$
\text{Variance}(\hat{f}) = \mathbb{E}[(\hat{f}(x) - \mathbb{E}[\hat{f}(x)])^2]
$$

## 트레이드오프의 이해

편향과 분산은 서로 반비례 관계에 있습니다. 즉, 편향을 줄이면 분산이 증가하고, 분산을 줄이면 편향이 증가하는 경향이 있습니다. 따라서, 모델의 예측 성능을 최적화하기 위해서는 편향과 분산 사이의 균형을 잘 맞추는 것이 중요합니다.

모델의 총 예측 오차는 다음과 같이 편향, 분산, 그리고 불확실성(irreducible error)의 합으로 표현됩니다:

$$
\text{MSE}(\hat{f}) = \text{Bias}(\hat{f})^2 + \text{Variance}(\hat{f}) + \text{Irreducible Error}
$$

여기서 MSE는 평균 제곱 오차(Mean Squared Error)를 의미합니다.

## 결론

편향-분산 트레이드오프는 머신러닝 모델의 성능을 이해하고 개선하는 데 핵심적인 역할을 합니다.

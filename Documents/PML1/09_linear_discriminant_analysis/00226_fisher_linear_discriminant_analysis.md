# 피셔의 선형 판별분석 (Fisher's Linear Discriminant Analysis)

피셔의 선형 판별분석(Fisher's Linear Discriminant Analysis, FLDA)은 통계학과 머신러닝에서 클래스 간의 분리를 최대화하기 위해 사용되는 선형 변환 기법입니다. 이 방법은 두 클래스의 데이터가 서로 분리되도록 고차원 데이터를 저차원으로 투영함으로써 분류 성능을 향상시키는 데 중점을 둡니다. 피셔의 선형 판별분석은 특히 두 클래스 간의 분산 비율을 최대화하여 최적의 분류 경계를 찾는 데 효과적입니다.

## 목차

1. [개요](#개요)
2. [수학적 배경](#수학적-배경)
   - [목표 함수](#목표-함수)
   - [최적화 과정](#최적화-과정)
3. [모델의 동작 원리](#모델의-동작-원리)
   - [투영 변환](#투영-변환)
   - [클래스 간 분산과 클래스 내 분산](#클래스-간-분산과-클래스-내-분산)
4. [파라미터 추정](#파라미터-추정)
   - [평균 벡터](#평균-벡터)
   - [공분산 행렬](#공분산-행렬)
5. [의사결정 경계](#의사결정-경계)
6. [장단점](#장단점)
7. [응용 사례](#응용-사례)
8. [참고문헌](#참고문헌)
9. [요약](#요약)

## 개요

피셔의 선형 판별분석은 주어진 데이터셋에서 두 클래스 간의 최대 분리를 달성하는 최적의 선형 결정을 찾는 방법입니다. 이 기법은 클래스 간의 거리와 클래스 내의 분산을 동시에 고려하여, 데이터 포인트를 한 차원으로 투영할 때 두 클래스가 최대한 분리되도록 합니다. FLDA는 특히 분류 문제에서 데이터의 차원 축소 및 특징 추출에 유용하게 사용됩니다.

## 수학적 배경

### 목표 함수

피셔의 선형 판별분석은 두 클래스 간의 분산 비율을 최대화하는 투영 벡터 $\mathbf{w}$를 찾는 것을 목표로 합니다. 이를 위해 클래스 간 분산(S_B)과 클래스 내 분산(S_W)을 정의하고, 이들의 비율을 최대화합니다.

$$
J(\mathbf{w}) = \frac{\mathbf{w}^T S_B \mathbf{w}}{\mathbf{w}^T S_W \mathbf{w}}
$$

여기서,
- $S_B$는 클래스 간 분산 행렬(Class Scatter Matrix)입니다.
- $S_W$는 클래스 내 분산 행렬(Within-Class Scatter Matrix)입니다.

### 최적화 과정

목표 함수 $J(\mathbf{w})$를 최대화하기 위해, 라그랑주 승수를 사용하여 최적화 문제를 풀게 됩니다. 이를 통해 최적의 투영 벡터 $\mathbf{w}$를 얻을 수 있습니다.

## 모델의 동작 원리

### 투영 변환

FLDA는 고차원 데이터를 저차원으로 투영하여 클래스 간의 분리를 극대화합니다. 투영 변환은 선형 결정을 통해 이루어지며, 투영된 데이터는 일차원 공간에서 두 클래스가 최대한 멀리 떨어지도록 배치됩니다.

$$
y = \mathbf{w}^T \mathbf{x}
$$

여기서, 
- $y$는 투영된 값,
- $\mathbf{w}$는 투영 벡터,
- $\mathbf{x}$는 원본 데이터 포인트입니다.

### 클래스 간 분산과 클래스 내 분산

- **클래스 간 분산 ($S_B$)**: 각 클래스의 평균 벡터 간의 거리. 두 클래스의 평균 벡터가 멀리 떨어질수록 클래스 간 분산이 큽니다.

$$
S_B = (\mu_1 - \mu_2)(\mu_1 - \mu_2)^T
$$

- **클래스 내 분산 ($S_W$)**: 각 클래스 내 데이터 포인트들이 평균 벡터 주변에 얼마나 흩어져 있는지. 클래스 내 분산이 작을수록 데이터가 뭉쳐 있습니다.

$$
S_W = S_{W1} + S_{W2}
$$

여기서,
$$
S_{Wk} = \sum_{i=1}^{N_k} (\mathbf{x}_i - \mu_k)(\mathbf{x}_i - \mu_k)^T
$$

## 파라미터 추정

### 평균 벡터

각 클래스 $k$에 대한 평균 벡터 $\mu_k$는 해당 클래스에 속하는 데이터 포인트들의 평균으로 추정됩니다.

$$
\mu_k = \frac{1}{N_k} \sum_{i=1}^{N_k} \mathbf{x}_i
$$

여기서, 
- $N_k$는 클래스 $k$에 속하는 데이터 포인트의 수입니다.

### 공분산 행렬

클래스 내 분산 행렬 $S_{Wk}$는 각 클래스의 공분산을 기반으로 계산됩니다.

$$
S_{Wk} = \sum_{i=1}^{N_k} (\mathbf{x}_i - \mu_k)(\mathbf{x}_i - \mu_k)^T
$$

## 의사결정 경계

투영된 값 $y$를 기준으로 의사결정 경계를 설정합니다. 두 클래스의 투영된 평균 값 사이의 중간점을 기준으로 분류를 수행합니다.

$$
y_0 = \frac{y_1 + y_2}{2}
$$

여기서,
- $y_1 = \mathbf{w}^T \mu_1$
- $y_2 = \mathbf{w}^T \mu_2$

새로운 데이터 포인트 $\mathbf{x}$가 투영되어 $y$로 변환되면, $y$가 $y_0$보다 크면 클래스 1, 작으면 클래스 2로 분류합니다.

## 장단점

### 장점

- **차원 축소**: 고차원 데이터를 저차원으로 효과적으로 축소하여 계산 효율성을 높일 수 있습니다.
- **분류 성능 향상**: 클래스 간의 분리를 최대화함으로써 분류기의 성능을 향상시킬 수 있습니다.
- **해석 용이성**: 투영 벡터 $\mathbf{w}$를 통해 데이터의 중요한 특징을 이해할 수 있습니다.

### 단점

- **가우시안 가정**: 데이터가 다변량 정규 분포를 따른다는 가정을 필요로 합니다.
- **두 클래스 간에만 적용 가능**: 기본적으로 이진 분류에 적합하며, 다중 클래스 문제에는 확장이 필요합니다.
- **공분산 행렬의 역행렬 계산**: 고차원 데이터에서는 공분산 행렬의 역행렬 계산이 어려울 수 있습니다.

## 응용 사례

피셔의 선형 판별분석은 다양한 분야에서 활용됩니다:

- **의료 진단**: 환자의 생체 신호 데이터를 기반으로 질병 유무를 분류.
- **얼굴 인식**: 얼굴 이미지 데이터를 투영하여 개인을 식별.
- **스팸 필터링**: 이메일의 특징을 분석하여 스팸 여부를 분류.
- **금융 사기 탐지**: 거래 데이터를 분석하여 사기 거래를 식별.
- **음성 인식**: 음성 데이터의 특징을 바탕으로 발화자를 식별하거나 내용을 분류.

## 참고문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

## 요약

피셔의 선형 판별분석(Fisher's Linear Discriminant Analysis)은 두 클래스 간의 최대 분리를 달성하기 위해 데이터의 차원을 저차원으로 투영하는 선형 변환 기법입니다. 이 방법은 클래스 간 분산을 최대화하고 클래스 내 분산을 최소화하는 방향으로 투영 벡터를 찾으며, 이를 통해 효과적인 이진 분류를 가능하게 합니다. FLDA는 의료, 얼굴 인식, 스팸 필터링 등 다양한 분야에서 활용되며, 데이터의 통계적 특성을 반영한 해석적 장점을 가지고 있습니다. 그러나 데이터가 다변량 정규 분포를 따르지 않을 경우 성능이 저하될 수 있으며, 다중 클래스 문제에 적용하기 위해서는 추가적인 확장이 필요합니다.
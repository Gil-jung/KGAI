# 이차 결정 경계 (Quadratic Decision Boundary)

이차 결정 경계(Quadratic Decision Boundary)는 분류 문제에서 두 클래스 사이의 비선형적인 경계를 형성하는 방법입니다. 이는 선형 결정 경계와 달리, 데이터의 복잡한 분포를 효과적으로 모델링할 수 있어 다양한 실제 문제에 적용됩니다. 이차 결정 경계는 주로 이차 판별 분석(Quadratic Discriminant Analysis, QDA)에서 사용되며, 각 클래스마다 고유한 공분산 행렬을 허용함으로써 유연한 분류가 가능합니다.

## 목차

1. [이차 결정 경계의 개요](#이차-결정-경계의-개요)
2. [수학적 배경](#수학적-배경)
3. [이차 판별 분석 (QDA)](#이차-판별-분석-qda)
4. [의사결정 경계의 도출](#의사결정-경계의-도출)
5. [장단점](#장단점)
6. [응용 사례](#응용-사례)
7. [참고문헌](#참고문헌)

## 이차 결정 경계의 개요

이차 결정 경계는 두 클래스 간의 분류를 위해 비선형적인 경계를 사용합니다. 이는 각 클래스의 데이터가 서로 다른 공분산 구조를 가질 때 효과적으로 작동하며, 데이터의 분포가 비대칭적이거나 곡선 형태를 띨 때 유리합니다. 예를 들어, 원형이나 타원형으로 분포된 데이터는 이차 결정 경계를 통해 효과적으로 구분할 수 있습니다.

## 수학적 배경

이차 결정 경계를 이해하기 위해서는 먼저 다변량 정규 분포와 판별 분석의 기본 개념을 이해해야 합니다.

### 다변량 정규 분포

클래스 $k$에 속하는 데이터 $\mathbf{x}$는 다음과 같은 다변량 정규 분포를 따른다고 가정합니다:

$$
p(\mathbf{x}|y=k) = \frac{1}{(2\pi)^{d/2} |\Sigma_k|^{1/2}} \exp\left( -\frac{1}{2} (\mathbf{x} - \mu_k)^T \Sigma_k^{-1} (\mathbf{x} - \mu_k) \right)
$$

여기서:
- $d$는 입력 데이터의 차원입니다.
- $\mu_k$는 클래스 $k$의 평균 벡터입니다.
- $\Sigma_k$는 클래스 $k$의 공분산 행렬입니다.

### 판별 분석의 기본 원리

판별 분석은 입력 데이터 $\mathbf{x}$가 주어졌을 때, 각 클래스 $y=k$에 속할 확률 $p(y=k|\mathbf{x})$을 계산하여 가장 높은 확률을 가진 클래스로 분류합니다. 이는 베이즈 정리를 이용하여 다음과 같이 표현됩니다:

$$
p(y=k|\mathbf{x}) = \frac{p(\mathbf{x}|y=k) \, p(y=k)}{p(\mathbf{x})}
$$

## 이차 판별 분석 (QDA)

이차 판별 분석(QDA)은 각 클래스마다 고유한 공분산 행렬 $\Sigma_k$을 가정하는 판별 분석의 한 형태입니다. 이는 선형 판별 분석(LDA)과의 주요 차이점으로, LDA는 모든 클래스가 동일한 공분산 행렬을 공유한다고 가정하는 반면, QDA는 각 클래스마다 다른 공분산 행렬을 가질 수 있습니다. 이로 인해 QDA는 더 유연한 결정 경계를 형성할 수 있습니다.

### QDA의 모델 가정

1. **클래스별 정규 분포**: 각 클래스는 고유한 평균 벡터 $\mu_k$와 공분산 행렬 $\Sigma_k$을 가지는 다변량 정규 분포를 따른다.
2. **확률적 분류**: 입력 데이터는 각 클래스에 속할 확률을 기반으로 분류된다.

## 의사결정 경계의 도출

두 클래스 $k=1$과 $k=2$ 간의 의사결정 경계를 도출하기 위해서는 다음 조건을 만족하는 $\mathbf{x}$를 찾습니다:

$$
p(y=1|\mathbf{x}) = p(y=2|\mathbf{x})
$$

이를 베이즈 정리에 대입하면 다음과 같이 됩니다:

$$
\frac{p(\mathbf{x}|y=1) \, p(y=1)}{p(\mathbf{x})} = \frac{p(\mathbf{x}|y=2) \, p(y=2)}{p(\mathbf{x})}
$$

양변에서 $p(\mathbf{x})$을 소거하면:

$$
p(\mathbf{x}|y=1) \, p(y=1) = p(\mathbf{x}|y=2) \, p(y=2)
$$

이를 로그를 취하면:

$$
\log p(\mathbf{x}|y=1) + \log p(y=1) = \log p(\mathbf{x}|y=2) + \log p(y=2)
$$

다변량 정규 분포의 로그 확률 밀도 함수를 대입하고 정리하면, 의사결정 경계는 다음과 같은 이차 방정식의 형태를 띱니다:

$$
(\mathbf{x} - \mu_1)^T \Sigma_1^{-1} (\mathbf{x} - \mu_1) - (\mathbf{x} - \mu_2)^T \Sigma_2^{-1} (\mathbf{x} - \mu_2) + \ln \frac{|\Sigma_2|}{|\Sigma_1|} + 2 \ln \frac{p(y=2)}{p(y=1)} = 0
$$

이 방정식은 $\mathbf{x}$에 대한 이차식이며, 두 클래스 간의 비선형적 경계를 형성합니다.

## 장단점

### 장점

- **유연성**: 각 클래스마다 다른 공분산 행렬을 허용함으로써 복잡한 데이터 분포를 효과적으로 모델링할 수 있습니다.
- **확률적 해석**: 분류를 확률적으로 수행하여 불확실성을 관리할 수 있습니다.
- **다양한 응용 가능성**: 비선형적인 분류 경계가 필요한 다양한 분야에 적용할 수 있습니다.

### 단점

- **파라미터 추정의 복잡성**: 각 클래스마다 고유한 공분산 행렬을 추정해야 하기 때문에, 파라미터의 수가 증가합니다. 이는 고차원 데이터에서 과적합(overfitting)의 위험을 증가시킬 수 있습니다.
- **계산 비용**: 공분산 행렬의 역행렬을 계산해야 하기 때문에, 계산 비용이 상대적으로 높습니다.
- **가우시안 가정**: 데이터가 실제로 다변량 정규 분포를 따르지 않을 경우, 모델의 성능이 저하될 수 있습니다.

## 응용 사례

이차 결정 경계는 다양한 분야에서 활용됩니다:

- **의료 진단**: 다양한 생체 신호나 의료 데이터를 기반으로 질병을 분류.
- **금융 사기 탐지**: 거래 데이터의 패턴을 분석하여 사기 여부를 판단.
- **이미지 분류**: 이미지의 특징을 분석하여 객체나 장면을 분류.
- **음성 인식**: 음성 데이터의 특징을 바탕으로 발화자를 식별하거나 내용을 분류.

## 참고문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.
# 선형 결정 경계 (Linear Decision Boundary)

선형 결정 경계(Linear Decision Boundary)는 분류 문제에서 두 클래스 사이를 구분하기 위해 선형 방정식을 사용하는 방법입니다. 이는 고차원 공간에서도 효율적으로 작동하며, 계산이 간단하고 해석이 용이한 장점이 있습니다. 선형 결정 경계는 주로 선형 판별 분석(Linear Discriminant Analysis, LDA)이나 로지스틱 회귀(Logistic Regression)와 같은 알고리즘에서 활용됩니다.

## 목차

1. [선형 결정 경계의 개요](#선형-결정-경계의-개요)
2. [수학적 배경](#수학적-배경)
3. [선형 결정 경계의 도출](#선형-결정-경계의-도출)
4. [선형 판별 분석 (LDA)와의 관계](#선형-판별-분석-lda와의-관계)
5. [장단점](#장단점)
6. [응용 사례](#응용-사례)
7. [참고문헌](#참고문헌)

## 선형 결정 경계의 개요

선형 결정 경계는 데이터 포인트를 분류하기 위해 직선(2차원), 평면(3차원), 또는 고차원의 초평면을 사용하는 방법입니다. 이 경계는 각 클래스의 특성을 고려하여 설정되며, 두 클래스 간의 최대 마진(Maximum Margin)을 유지하거나 특정 분류 기준을 만족하도록 조정됩니다. 선형 결정 경계는 데이터가 선형적으로 분리 가능할 때 효과적으로 작동합니다.

## 수학적 배경

선형 결정 경계는 주어진 입력 벡터 $\mathbf{x} \in \mathbb{R}^d$에 대해 클래스를 예측하는 방식입니다. 일반적으로 다음과 같은 형태의 결정 함수를 정의합니다:

$$
f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b
$$

여기서:
- $\mathbf{w} \in \mathbb{R}^d$는 가중치 벡터입니다.
- $b \in \mathbb{R}$는 편향(bias) 항입니다.

결정 경계는 $f(\mathbf{x}) = 0$인 지점으로 정의되며, 이를 통해 클래스 간의 구분이 이루어집니다.

## 선형 결정 경계의 도출

### 1. 이진 분류에서의 결정 규칙

이진 분류 문제에서 클래스 레이블을 $y \in \{0, 1\}$로 설정할 때, 결정 규칙은 다음과 같이 정의됩니다:

$$
y = \begin{cases}
1 & \text{if } \mathbf{w}^T \mathbf{x} + b \geq 0 \\
0 & \text{otherwise}
\end{cases}
$$

### 2. 최대 마진 원칙 (Maximum Margin)

서포트 벡터 머신(Support Vector Machine, SVM)에서는 최대 마진 원칙을 사용하여 결정 경계를 찾습니다. 마진은 결정 경계와 가장 가까운 데이터 포인트(서포트 벡터) 간의 거리입니다. 최대 마진을 유지함으로써 모델의 일반화 성능을 향상시킬 수 있습니다.

마진을 최대화하기 위해 최적화 문제를 설정하면 다음과 같습니다:

$$
\begin{aligned}
& \underset{\mathbf{w}, b}{\text{maximize}} && \frac{2}{\|\mathbf{w}\|} \\
& \text{subject to} && y^{(i)} (\mathbf{w}^T \mathbf{x}^{(i)} + b) \geq 1, \quad \forall i
\end{aligned}
$$

### 3. 로지스틱 회귀와의 연계

로지스틱 회귀(Logistic Regression)에서도 선형 결정 경계를 사용합니다. 로지스틱 회귀는 시그모이드 함수(Sigmoid Function)를 통해 확률을 모델링하며, 결정 경계는 $\sigma(\mathbf{w}^T \mathbf{x} + b) = 0.5$인 지점에서 형성됩니다. 이는 곧 $\mathbf{w}^T \mathbf{x} + b = 0$과 동일합니다.

$$
\sigma(z) = \frac{1}{1 + e^{-z}} \quad \Rightarrow \quad \sigma(\mathbf{w}^T \mathbf{x} + b) = 0.5 \quad \Rightarrow \quad \mathbf{w}^T \mathbf{x} + b = 0
$$

## 선형 판별 분석 (LDA)와의 관계

선형 판별 분석(LDA)은 데이터가 다변량 정규 분포를 따른다는 가정 하에 클래스 간의 분산을 최대화하고 클래스 내의 분산을 최소화하는 방향으로 데이터를 투영하여 선형 결정 경계를 도출합니다. LDA는 다음과 같은 조건을 가정합니다:

1. 각 클래스는 다변량 정규 분포를 따른다.
2. 모든 클래스는 동일한 공분산 행렬을 가진다.

LDA에서 도출된 결정 경계는 선형이며, 이는 각 클래스의 평균 벡터와 공분산 행렬을 기반으로 계산됩니다.

## 장단점

### 장점

- **단순성**: 수학적으로 단순하고 구현이 용이합니다.
- **빠른 학습 속도**: 계산 복잡도가 낮아 대규모 데이터에도 적용 가능합니다.
- **해석 용이성**: 결정 경계가 선형이므로 모델의 해석이 직관적입니다.
- **효율성**: 고차원 데이터에서도 효율적으로 작동합니다.

### 단점

- **선형성의 한계**: 데이터가 비선형적으로 분포된 경우 성능이 저하됩니다.
- **가우시안 가정**: LDA와 같은 방법은 데이터가 특정 분포를 따른다는 가정을 필요로 합니다.
- **특징 간 독립성**: 일부 알고리즘은 특징 간 독립성을 가정하기도 합니다.

## 응용 사례

선형 결정 경계는 다양한 분야에서 활용됩니다:

- **스팸 필터링**: 이메일의 특징을 기반으로 스팸 여부를 분류.
- **의료 진단**: 환자의 증상 데이터를 분석하여 질병을 예측.
- **금융 사기 탐지**: 거래 패턴을 분석하여 사기 거래를 식별.
- **이미지 분류**: 이미지의 특징을 기반으로 객체를 분류.
- **문서 분류**: 텍스트 데이터를 분석하여 문서의 주제를 분류.

## 참고문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.
# 가역 변환 (전단사)

## 개요
가역 변환(invertible transformation), 또는 전단사 함수(bijective function)는 수학과 컴퓨터 과학에서 중요한 개념으로, 주어진 함수가 전사적이고 단사적일 때 가역성을 갖는다고 합니다. 즉, 함수가 일대일 대응을 이루며, 모든 입력값에 대해 고유한 출력값을 가지며, 역함수가 존재한다는 것을 의미합니다.

## 정의

### 1. 단사 함수 (Injective Function)
단사 함수는 서로 다른 두 입력값에 대해 서로 다른 출력값을 갖는 함수입니다. 즉, \( f(x_1) = f(x_2) \)이면 \( x_1 = x_2 \)가 성립하는 함수입니다. 이 성질은 역함수의 존재를 위한 첫 번째 조건입니다.

### 2. 전사 함수 (Surjective Function)
전사 함수는 함수의 모든 출력값이 목표 집합의 모든 요소를 포함하는 함수입니다. 즉, 모든 출력값 \( y \)에 대해 적어도 하나의 입력값 \( x \)가 존재하여 \( f(x) = y \)가 성립하는 함수입니다. 이 성질은 역함수의 존재를 위한 두 번째 조건입니다.

### 3. 전단사 함수 (Bijective Function)
단사 함수와 전사 함수의 성질을 모두 만족하는 함수는 전단사 함수라 불리며, 이러한 함수에 대해서는 역함수가 존재합니다. 따라서 \( f: X \rightarrow Y \)가 전단사라면, 그 역함수 \( f^{-1}: Y \rightarrow X \)가 존재하여 \( f(f^{-1}(y)) = y \) 및 \( f^{-1}(f(x)) = x \)를 만족합니다.

## 가역 변환의 중요성
가역 변환은 여러 응용 분야에서 중요한 역할을 합니다. 특히, 데이터 변환, 암호화, 기계 학습 모델링에서 자주 사용됩니다. 예를 들어, 데이터의 차원을 축소하거나 확대할 때 전단사 함수를 통해 정보 손실 없이 변환이 가능하며, 암호화 알고리즘에서도 원래 데이터를 복원하는 과정에 가역 변환이 필수적입니다.

### 확률론에서의 가역 변환
확률 분포의 변환에서도 가역 변환은 중요한 역할을 합니다. 만약 확률 변수 \( X \)가 가역 변환 \( g \)를 통해 \( Y = g(X) \)로 변환된다면, \( Y \)의 확률 밀도 함수는 \( X \)의 확률 밀도 함수와 변환 함수의 도함수를 이용해 계산됩니다. 이는 변수 변환을 통해 복잡한 확률 분포를 단순화하거나, 역변환을 통해 분석할 수 있는 기반을 제공합니다.

## 참고 문헌
- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

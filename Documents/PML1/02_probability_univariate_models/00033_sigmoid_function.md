# 시그모이드(로지스틱) 함수

시그모이드 함수는 **로지스틱 회귀**와 **인공 신경망**에서 주로 사용되는 중요한 수학적 함수입니다. 이 함수는 S자 형태의 곡선을 그리며, 주어진 입력 값을 0과 1 사이의 값으로 매핑합니다. 이는 확률적인 해석을 가능하게 하며, 이진 분류 문제에서 자주 사용됩니다.

## 함수 정의

시그모이드 함수는 다음과 같은 수식으로 정의됩니다:

\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]

여기서:
- \(x\)는 입력값입니다.
- \(e\)는 자연로그의 밑(approximately 2.718)입니다.

## 함수의 특징

1. **출력 범위**: 함수의 출력은 항상 0과 1 사이에 위치합니다. 이 특징은 출력 값을 확률로 해석할 수 있게 해주며, 주로 이진 분류 문제에서 사용됩니다.

2. **S자 곡선**: 함수의 그래프는 S자 형태로, \(x\)가 증가함에 따라 출력 값이 1에 가까워지고, \(x\)가 감소하면 출력 값이 0에 가까워집니다. 특히, \(x = 0\)에서 함수 값은 0.5입니다.

3. **대칭성**: 시그모이드 함수는 \(x = 0\)을 기준으로 대칭적이며, 이로 인해 함수는 중립적인 값에서 중심을 형성합니다.

4. **기울기 소실 문제**: 시그모이드 함수는 신경망에서 사용될 때, 입력 값이 매우 크거나 작을 경우 기울기(gradient)가 매우 작아지는 문제가 있습니다. 이는 학습 과정에서 가중치 업데이트가 제대로 이루어지지 않는 "기울기 소실 문제"를 초래할 수 있습니다.

## 도함수

시그모이드 함수의 도함수는 다음과 같이 표현됩니다:

\[
\sigma'(x) = \sigma(x) \cdot (1 - \sigma(x))
\]

이 도함수는 신경망 학습에서 중요한 역할을 합니다. 도함수를 통해 역전파(backpropagation) 과정에서 가중치 조정에 필요한 기울기를 계산할 수 있습니다.

## 활용 사례

1. **로지스틱 회귀**: 시그모이드 함수는 로지스틱 회귀 모델에서 사용되어, 이진 분류 문제를 해결합니다. 모델은 주어진 입력 데이터가 특정 클래스에 속할 확률을 예측합니다.

2. **신경망의 활성화 함수**: 인공 신경망에서 시그모이드 함수는 뉴런의 활성화 함수로 자주 사용되며, 뉴런의 출력 값을 결정합니다.

3. **확률적 해석**: 시그모이드 함수의 출력 값은 0과 1 사이의 확률로 해석될 수 있어, 불확실성을 다루는 문제에서 유용하게 사용됩니다.

## 시각적 표현

시그모이드 함수의 그래프는 다음과 같은 형태를 가집니다:

```plaintext
     |                _________
  1  |              /
     |            /
     |          /
  0.5|--------/
     |      /
     |    /
  0  |___/_______________
          -∞    0     ∞

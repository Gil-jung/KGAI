# 가우스 분포에서의 회귀

## 개요
가우스 분포에서의 회귀(Gaussian Regression)는 선형 회귀 모델을 확률론적 관점에서 바라본 방법론입니다. 이는 종종 **가우시안 선형 회귀** 또는 **최대우도 추정**(Maximum Likelihood Estimation)과 같은 맥락에서 논의됩니다. 이 기법은 회귀 문제를 해결하는 데 사용되며, 데이터가 정규(가우스) 분포를 따른다는 가정을 바탕으로 합니다.

## 기본 개념
가우스 분포에서의 회귀는 다음과 같은 가정을 기반으로 합니다:

- **선형 모델**: 종속 변수 \( y \)는 입력 변수 \( x \)의 선형 결합으로 표현됩니다. 즉, 
  \[
  y = \beta_0 + \beta_1 x + \epsilon
  \]
  여기서 \( \epsilon \)은 오류(또는 잡음)로, 정규 분포 \( N(0, \sigma^2) \)를 따릅니다.

- **정규 분포 가정**: 오차 \( \epsilon \)는 평균이 0이고, 분산이 \( \sigma^2 \)인 정규 분포를 따릅니다. 따라서, 종속 변수 \( y \)는 주어진 \( x \)에 대해 정규 분포를 따르며, 그 평균은 \( \beta_0 + \beta_1 x \)가 됩니다.

## 최대우도 추정
가우스 분포에서의 회귀에서는 **최대우도 추정(MLE, Maximum Likelihood Estimation)** 방법을 사용하여 모델의 파라미터 \( \beta_0 \), \( \beta_1 \), \( \sigma^2 \)를 추정합니다. 이 방법은 주어진 데이터에서 발생할 확률을 최대화하는 파라미터 값을 찾는 과정입니다.

최대우도 추정은 다음과 같은 과정을 따릅니다:

1. **우도 함수 작성**: 각 데이터 포인트 \( (x_i, y_i) \)에 대해 우도 함수는 다음과 같이 정의됩니다.
   \[
   L(\beta_0, \beta_1, \sigma^2) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - (\beta_0 + \beta_1 x_i))^2}{2\sigma^2}\right)
   \]

2. **로그 우도 함수**: 계산의 편의성을 위해 로그 우도 함수를 사용합니다.
   \[
   \log L(\beta_0, \beta_1, \sigma^2) = -\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2
   \]

3. **최대화**: 이 로그 우도 함수를 최대화하여 \( \beta_0 \), \( \beta_1 \), \( \sigma^2 \)의 값을 추정합니다.

## 가우스 회귀의 특징
- **모델의 해석 용이성**: 선형 모델로서 \( \beta_0 \), \( \beta_1 \)의 해석이 명확하며, 이는 절편과 기울기를 의미합니다.
- **정규 분포 가정**: 데이터가 정규 분포를 따르는 경우 매우 적합한 방법론입니다.
- **오차의 정규성 가정**: 오차가 정규 분포를 따르므로, 이 가정을 위배하는 경우에는 다른 모델을 고려해야 할 수도 있습니다.

## 결론
가우스 분포에서의 회귀는 선형 회귀 모델을 확률론적 프레임워크로 일반화한 방법으로, 정규 분포를 가정하고 최대우도 추정을 통해 모델 파라미터를 추정합니다. 이 방법은 데이터가 이러한 가정에 부합할 때 매우 유용하며, 실무에서 널리 사용됩니다.

## 참고 문헌
- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2012). *Machine Learning: A Probabilistic Perspective*. MIT Press.

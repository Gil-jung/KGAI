# 정규화 상호 정보 (Normalized Mutual Information, NMI)

**정규화 상호 정보(Normalized Mutual Information, NMI)**는 두 확률 변수 사이의 의존성을 측정하는 상호 정보(Mutual Information, MI)를 정규화한 값입니다. NMI는 상호 정보의 값을 두 변수의 개별 엔트로피 값으로 나누어, 상호 정보의 상대적 중요성을 평가할 수 있도록 합니다. NMI는 두 변수 간의 관계를 정량적으로 비교하고, 변수의 스케일 차이나 샘플 크기 차이로 인한 왜곡을 줄일 수 있는 장점이 있습니다.

## 정규화 상호 정보의 정의

정규화 상호 정보는 여러 가지 방식으로 정의될 수 있지만, 일반적인 정의 중 하나는 다음과 같습니다:

$$
\text{NMI}(X; Y) = \frac{I(X; Y)}{\sqrt{H(X) \cdot H(Y)}}
$$

여기서:

- $I(X; Y)$는 확률 변수 $X$와 $Y$의 **상호 정보**입니다.
- $H(X)$와 $H(Y)$는 각각 $X$와 $Y$의 **엔트로피**입니다.

이 정의는 상호 정보를 두 변수의 엔트로피 값으로 정규화하여, 변수 간의 의존성을 0과 1 사이의 값으로 표현합니다. NMI 값은 0에서 1 사이의 범위를 가지며, 0은 두 변수가 서로 독립임을 의미하고, 1은 두 변수가 완전히 동일함을 의미합니다.

또한, NMI는 다음과 같이 두 변수의 엔트로피와 결합 엔트로피를 활용하여 정의될 수도 있습니다:

$$
\text{NMI}(X; Y) = \frac{2 \cdot I(X; Y)}{H(X) + H(Y)}
$$

## 정규화 상호 정보의 해석

NMI는 데이터의 분포나 스케일 차이에 영향을 받지 않으므로, 다양한 데이터 셋 간의 상호 정보 값을 공정하게 비교할 수 있습니다. 이로 인해 NMI는 클러스터링 평가, 특징 선택(feature selection), 그리고 데이터 분석 등의 다양한 분야에서 널리 사용됩니다.

1. **클러스터링 평가**: 클러스터링 결과를 평가할 때, NMI는 클러스터링 결과와 실제 라벨 간의 유사성을 측정하는 데 유용합니다. 높은 NMI 값은 클러스터링 결과가 실제 라벨과 잘 일치함을 나타냅니다.

2. **특징 선택**: 머신러닝에서 NMI는 특정 특징이 타겟 변수와 얼마나 연관성이 있는지를 평가하는 데 사용됩니다. NMI 값이 높을수록 해당 특징이 타겟 변수와 강하게 연관되어 있음을 나타냅니다.

3. **비교 분석**: 서로 다른 데이터 셋 간의 상호 의존성을 비교할 때, NMI는 변수 간 관계의 강도를 공정하게 비교하는 수단이 될 수 있습니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

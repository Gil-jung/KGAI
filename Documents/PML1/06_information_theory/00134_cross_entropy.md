# 교차 엔트로피 (Cross-Entropy)

## 개요

교차 엔트로피(Cross-Entropy)는 두 확률 분포 간의 차이를 측정하는 방법으로, 주로 기계 학습과 정보 이론에서 사용됩니다. 특히 분류 문제에서 모델의 예측과 실제 레이블 간의 차이를 측정하는 손실 함수로 널리 활용됩니다.

## 1. **교차 엔트로피의 정의**

교차 엔트로피는 두 확률 분포 $P$와 $Q$ 간의 차이를 나타내며, 주어진 데이터 샘플이 실제로 $P$에서 나왔을 때, 그 샘플이 $Q$에 의해 얼마나 잘 설명되는지를 측정합니다.

교차 엔트로피는 다음과 같이 정의됩니다:

$$
H(P, Q) = - \sum_{x \in \mathcal{X}} P(x) \log Q(x)
$$

여기서:
- $P(x)$는 실제 데이터의 분포(또는 실제 레이블의 확률 분포),
- $Q(x)$는 모델이 예측한 확률 분포입니다.

교차 엔트로피는 두 분포 간의 불일치를 측정하며, $P$와 $Q$가 같을수록 교차 엔트로피가 낮아집니다.

## 2. **교차 엔트로피의 직관적 이해**

교차 엔트로피는 주어진 예측 분포 $Q$가 실제 분포 $P$를 얼마나 잘 설명하는지를 평가합니다. 예를 들어, $P$는 주어진 샘플의 실제 레이블이 1인 확률이고, $Q$는 모델이 예측한 해당 샘플이 1인 확률이라고 합시다. 이때 교차 엔트로피는 모델의 예측이 실제 레이블과 얼마나 잘 맞는지를 측정하게 됩니다.

이상적으로는 $Q(x) = P(x)$가 되어야 하며, 이때 교차 엔트로피는 최소가 됩니다. 하지만, 모델이 잘못된 예측을 할수록 교차 엔트로피 값은 커지게 됩니다.

## 3. **교차 엔트로피 손실 함수**

딥러닝에서 교차 엔트로피는 손실 함수로 많이 사용됩니다. 주로 분류 문제에서 사용되며, 이진 분류(binary classification)와 다중 클래스 분류(multiclass classification)에서 다르게 정의됩니다.

### 이진 분류에서의 교차 엔트로피

이진 분류 문제에서 교차 엔트로피는 다음과 같이 정의됩니다:

$$
H(P, Q) = - \left[ y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \right]
$$

여기서:
- $y$는 실제 레이블(0 또는 1),
- $\hat{y}$는 모델이 예측한 확률(0과 1 사이의 값).

### 다중 클래스 분류에서의 교차 엔트로피

다중 클래스 분류 문제에서는 다음과 같이 교차 엔트로피가 정의됩니다:

$$
H(P, Q) = - \sum_{i=1}^{C} y_i \log(\hat{y}_i)
$$

여기서:
- $C$는 클래스의 수,
- $y_i$는 실제 레이블(해당 클래스에 해당하면 1, 그렇지 않으면 0),
- $\hat{y}_i$는 해당 클래스에 대한 모델의 예측 확률.

이 표현식은 실제 레이블에 해당하는 클래스의 예측 확률을 사용해 손실을 계산합니다.

## 4. **교차 엔트로피와 Kullback-Leibler(KL) 발산**

교차 엔트로피는 KL 발산(Kullback-Leibler Divergence)과 밀접한 관련이 있습니다. KL 발산은 다음과 같이 정의됩니다:

$$
D_{KL}(P || Q) = \sum_{x \in \mathcal{X}} P(x) \log \frac{P(x)}{Q(x)}
$$

교차 엔트로피는 실제 엔트로피 $H(P)$와 KL 발산의 합으로 표현될 수 있습니다:

$$
H(P, Q) = H(P) + D_{KL}(P || Q)
$$

이는 교차 엔트로피가 모델의 예측이 실제 분포로부터 얼마나 벗어났는지를 측정하는 방법임을 의미합니다.

## 5. **교차 엔트로피의 응용**

교차 엔트로피는 다음과 같은 다양한 분야에서 응용됩니다:

- **딥러닝**: 분류 모델의 학습에서 손실 함수로 자주 사용됩니다.
- **정보 이론**: 두 확률 분포 간의 차이를 측정하는 데 사용됩니다.
- **통계학**: 확률 모델의 적합도를 평가하는 지표로 활용됩니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

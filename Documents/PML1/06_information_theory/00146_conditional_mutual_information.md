# 조건부 상호 정보

**조건부 상호 정보(Conditional Mutual Information, CMI)**는 두 확률 변수 $X$와 $Y$ 사이의 상호 정보가 제3의 변수 $Z$에 조건화된 경우를 측정하는 지표입니다. 이는 $Z$가 주어진 상황에서 $X$와 $Y$ 간의 의존성을 나타내며, $Z$가 주어진 상황에서 $X$와 $Y$ 사이에 얼마만큼의 정보가 공유되는지를 의미합니다.

## 정의

조건부 상호 정보는 다음과 같이 정의됩니다:

$$
I(X; Y \mid Z) = H(X \mid Z) - H(X \mid Y, Z)
$$

여기서,

- $H(X \mid Z)$는 $Z$가 주어진 상황에서 $X$의 **조건부 엔트로피**입니다.
- $H(X \mid Y, Z)$는 $Y$와 $Z$가 주어진 상황에서 $X$의 **조건부 엔트로피**입니다.

다른 표현으로, 조건부 상호 정보는 다음과 같은 형태로도 나타낼 수 있습니다:

$$
I(X; Y \mid Z) = H(X \mid Z) + H(Y \mid Z) - H(X, Y \mid Z)
$$

이 식은 $Z$가 주어졌을 때의 $X$와 $Y$의 개별 엔트로피와 $X$와 $Y$의 결합 엔트로피 간의 차이를 나타냅니다.

## 해석

조건부 상호 정보는 다음과 같은 방식으로 해석할 수 있습니다:

1. **$I(X; Y \mid Z) = 0$**: $Z$가 주어진 상황에서 $X$와 $Y$는 **독립적**임을 의미합니다. 즉, $Z$의 정보를 고려할 때, $X$와 $Y$는 서로에 대해 더 이상 추가적인 정보를 제공하지 않습니다.

2. **$I(X; Y \mid Z) > 0$**: $Z$가 주어진 상황에서 $X$와 $Y$ 사이에 **의존성**이 존재함을 의미합니다. 이 경우 $X$와 $Y$ 간의 정보 교환이 존재하며, $Z$가 주어진 조건에서도 $X$와 $Y$ 사이의 상호 의존성이 남아 있음을 나타냅니다.

3. **상호 정보와의 관계**: 조건부 상호 정보는 상호 정보 $I(X; Y)$의 일반화된 형태로 볼 수 있습니다. $Z$가 주어지지 않은 경우, 즉 $Z$가 공통적인 배경 지식이 없는 경우, 조건부 상호 정보는 일반적인 상호 정보 $I(X; Y)$와 동일하게 됩니다.

$$
I(X; Y) = I(X; Y \mid \emptyset)
$$

## 응용

조건부 상호 정보는 다양한 분야에서 활용됩니다. 예를 들어, **정보 전달 시스템**에서 노이즈가 존재하는 상황에서 두 신호 간의 상호 정보를 분석하는 데 사용될 수 있습니다. 또한, **머신 러닝**에서는 특정 피처가 다른 피처나 타겟 변수와 조건부 상호 정보를 가지는지를 평가하여 모델의 성능을 향상시킬 수 있습니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

# 엔트로피(Entropy)

## 개요

엔트로피(Entropy)는 정보 이론, 통계 물리학, 기계 학습 등 다양한 분야에서 중요한 개념으로, 시스템의 불확실성을 측정하는 척도입니다. 특히 정보 이론에서 엔트로피는 주어진 확률 분포에서 얻을 수 있는 정보의 평균량을 나타냅니다.

## 1. **정보 이론에서의 엔트로피**

클로드 섀넌(Claude Shannon)이 정보 이론에서 정의한 엔트로피는 랜덤 변수 $X$의 확률 분포 $P(X)$에 따라 결정되며, 다음과 같이 수식으로 표현됩니다.

$$
H(X) = - \sum_{x \in \mathcal{X}} P(x) \log P(x)
$$

여기서:
- $H(X)$는 랜덤 변수 $X$의 엔트로피입니다.
- $\mathcal{X}$는 $X$가 취할 수 있는 모든 가능한 값들의 집합입니다.
- $P(x)$는 $X$가 값 $x$를 가질 확률입니다.
- 로그는 보통 밑이 2인 로그(log base 2)를 사용하며, 이 경우 엔트로피는 비트 단위로 측정됩니다.

이 수식은 주어진 확률 분포 하에서 데이터의 불확실성을 측정합니다. 엔트로피가 높을수록 데이터가 불확실하며, 엔트로피가 낮을수록 데이터가 예측 가능하다는 것을 의미합니다.

## 2. **엔트로피의 성질**

- **비음수성(Non-negativity):** 엔트로피는 항상 0 이상의 값을 가지며, $H(X) = 0$일 때는 $X$가 확정적(즉, 불확실성이 없는)인 경우를 나타냅니다.
- **최대 엔트로피(Maximum Entropy):** 모든 사건이 동일한 확률을 가질 때, 엔트로피는 최대가 됩니다. 예를 들어, $X$가 두 가지 값(예: 동전의 앞과 뒤)을 동일한 확률로 가질 경우, 엔트로피는 1 비트가 됩니다.
- **조건부 엔트로피(Conditional Entropy):** 조건부 엔트로피 $H(X|Y)$는 다른 랜덤 변수 $Y$가 주어졌을 때 $X$의 불확실성을 측정합니다. 이는 $Y$에 대한 정보가 주어졌을 때 $X$에 대한 추가적인 불확실성을 나타냅니다.

## 3. **기계 학습에서의 엔트로피**

기계 학습에서 엔트로피는 주로 의사결정나무(decision tree) 알고리즘에서 사용됩니다. 정보 이득(Information Gain)은 부모 노드와 자식 노드 간의 엔트로피 차이를 측정하여, 각 분할이 데이터의 불확실성을 얼마나 줄이는지를 평가합니다. 의사결정나무는 정보 이득이 최대화되는 방향으로 데이터를 분할하여 학습합니다.

정보 이득은 다음과 같이 정의됩니다.

$$
\text{Information Gain} = H(X) - \sum_{i} P(i) H(X|Y=i)
$$

여기서 $H(X)$는 분할 이전의 엔트로피, $H(X|Y=i)$는 분할 후의 조건부 엔트로피를 나타냅니다.

## 4. **물리학에서의 엔트로피**

통계 물리학에서 엔트로피는 열역학적 시스템의 무질서도의 척도로 사용됩니다. 물리학적 엔트로피는 볼츠만 상수 $k_B$와 다음과 같은 관계를 가집니다.

$$
S = k_B \ln \Omega
$$

여기서:
- $S$는 엔트로피,
- $k_B$는 볼츠만 상수,
- $\Omega$는 주어진 에너지 상태에서 가능한 미시적 구성의 수입니다.

이 수식은 시스템의 미시적 상태의 수가 증가할수록 엔트로피가 증가함을 나타냅니다. 열역학적 엔트로피는 정보 이론에서의 엔트로피와 직접적으로 관련이 있으며, 두 개념 모두 시스템의 불확실성이나 무질서를 측정하는 데 사용됩니다.

## 5. **엔트로피의 응용**

- **데이터 압축:** 엔트로피는 최적의 데이터 압축률을 결정하는 데 중요한 역할을 합니다. 엔트로피가 낮은 데이터는 더 높은 압축률을 가질 수 있습니다.
- **암호화:** 엔트로피는 암호화 시스템의 보안성을 평가하는 데 사용됩니다. 높은 엔트로피를 가진 암호는 더 예측 불가능하고 안전합니다.
- **의사결정:** 의사결정 과정에서 엔트로피는 불확실성을 정량화하여, 다양한 선택지 중에서 최적의 결정을 내리는 데 도움을 줍니다.

## 결론

엔트로피는 다양한 학문 분야에서 중요한 역할을 하는 개념으로, 불확실성이나 무질서를 측정하는 데 사용됩니다. 정보 이론에서의 엔트로피는 확률 분포의 불확실성을 나타내며, 기계 학습과 물리학 등에서 폭넓게 응용되고 있습니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

# "일반화 상관계수"로서의 MI

상호 정보(Mutual Information, MI)는 정보 이론에서 두 확률 변수 사이의 의존성을 측정하는 지표로, 이는 두 변수 간의 상관 관계를 일반화한 것으로 볼 수 있습니다. **상호 정보**는 상관계수의 개념을 확률 분포의 관점에서 확장한 것이며, 두 변수 간의 비선형적 관계까지 포착할 수 있다는 점에서 유용합니다.

## 상호 정보(MI)의 정의

두 확률 변수 $X$와 $Y$에 대한 상호 정보는 다음과 같이 정의됩니다:

$$
I(X; Y) = \sum_{x \in X} \sum_{y \in Y} p(x, y) \log \left(\frac{p(x, y)}{p(x)p(y)}\right)
$$

여기서:

- $p(x, y)$는 $X$와 $Y$의 **결합 확률 분포**입니다.
- $p(x)$와 $p(y)$는 각각 $X$와 $Y$의 **주변 확률 분포**입니다.

상호 정보는 $X$와 $Y$ 사이의 **공동 엔트로피**와 **개별 엔트로피** 간의 차이로도 표현될 수 있습니다:

$$
I(X; Y) = H(X) + H(Y) - H(X, Y)
$$

여기서 $H(X)$와 $H(Y)$는 각각 $X$와 $Y$의 엔트로피이고, $H(X, Y)$는 결합 엔트로피입니다.

## 상관계수와의 비교

상관계수는 두 변수 간의 선형적 관계를 측정하는 지표로, 두 변수 간의 관계가 직선 형태로 나타나는 경우 유용합니다. 그러나 상관계수는 두 변수 간의 비선형적 관계를 잘 포착하지 못합니다. 이에 비해, 상호 정보는 비선형적 관계까지 포착할 수 있습니다.

상호 정보는 다음과 같은 장점을 가집니다:

- **비선형 관계 포착**: 상관계수는 선형 관계를 주로 다루지만, 상호 정보는 비선형적 종속성까지도 효과적으로 포착할 수 있습니다.
- **정보량 측정**: 상호 정보는 두 변수 간의 정보 교환량을 측정하므로, 두 변수가 얼마나 많은 정보를 공유하는지를 정량적으로 나타낼 수 있습니다.

이 때문에 상호 정보는 **일반화된 상관계수**로 해석될 수 있습니다. 상관계수는 MI의 특정한 경우로 볼 수 있으며, 상호 정보는 두 변수 간의 의존성에 대한 더 포괄적인 분석을 가능하게 합니다.

## 예시 및 응용

1. **비선형 관계의 탐지**: 예를 들어, 두 변수 간의 관계가 선형이 아닌 경우, 상호 정보는 상관계수보다 더 높은 값을 가질 수 있습니다. 이는 상호 정보가 두 변수 사이의 복잡한 관계를 더 잘 설명할 수 있음을 의미합니다.
  
2. **특징 선택**: 머신러닝에서 상호 정보는 특징 선택(feature selection) 과정에서 중요한 역할을 합니다. 높은 상호 정보를 가진 특징은 타겟 변수와 강하게 연관되어 있어 유용한 예측 변수가 될 가능성이 큽니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

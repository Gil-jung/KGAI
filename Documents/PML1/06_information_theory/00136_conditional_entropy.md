# 조건부 엔트로피 (Conditional Entropy)

## 개요

조건부 엔트로피(Conditional Entropy)는 두 확률 변수 $X$와 $Y$가 있을 때, $Y$가 주어졌을 때 $X$에 남아 있는 불확실성을 측정하는 정보 이론의 개념입니다. 이는 $Y$에 대한 정보가 주어졌을 때 $X$에 대한 불확실성이 얼마나 줄어드는지를 나타냅니다. 조건부 엔트로피는 주어진 정보에 따라 데이터의 불확실성을 분석하는 데 중요한 역할을 합니다.

## 1. **조건부 엔트로피의 정의**

조건부 엔트로피 $H(X|Y)$는 변수 $Y$가 주어졌을 때 변수 $X$의 불확실성을 측정하는 척도입니다. 수식으로는 다음과 같이 정의됩니다:

$$
H(X|Y) = - \sum_{y \in \mathcal{Y}} P(Y=y) \sum_{x \in \mathcal{X}} P(X=x|Y=y) \log P(X=x|Y=y)
$$

여기서:
- $P(Y=y)$는 $Y$가 특정 값 $y$를 가질 확률을 나타냅니다.
- $P(X=x|Y=y)$는 $Y=y$일 때 $X=x$일 조건부 확률을 의미합니다.
- $\mathcal{X}$와 $\mathcal{Y}$는 각각 $X$와 $Y$의 가능한 값들의 집합입니다.

조건부 엔트로피는 $Y$의 정보를 활용하여 $X$에 대한 불확실성을 줄이는 방법을 나타내며, $X$와 $Y$가 독립적일 때는 $H(X|Y) = H(X)$가 됩니다.

## 2. **조건부 엔트로피의 특성**

### 조건부 엔트로피와 결합 엔트로피
조건부 엔트로피는 결합 엔트로피와 밀접한 관계가 있습니다. 결합 엔트로피 $H(X, Y)$는 두 변수 $X$와 $Y$의 전체 불확실성을 나타내며, 다음과 같이 표현될 수 있습니다:

$$
H(X, Y) = H(Y) + H(X|Y)
$$

이 수식은 결합 엔트로피가 $Y$의 엔트로피와 $Y$가 주어졌을 때의 $X$의 조건부 엔트로피로 분해될 수 있음을 보여줍니다.

### 상호 정보와의 관계
조건부 엔트로피는 상호 정보(Mutual Information)와도 관련이 있습니다. 상호 정보는 $X$와 $Y$ 간의 종속성을 나타내며, 다음과 같이 정의됩니다:

$$
I(X; Y) = H(X) - H(X|Y)
$$

여기서 $I(X; Y)$는 $X$와 $Y$ 사이의 정보 교환량을 나타내며, 상호 정보가 클수록 두 변수 사이의 종속성이 큽니다.

## 3. **조건부 엔트로피의 응용**

조건부 엔트로피는 다음과 같은 분야에서 활용됩니다:

- **통신 이론**: 잡음이 있는 환경에서 메시지가 전달될 때, 잡음이 제거된 후에도 남아 있는 메시지의 불확실성을 분석하는 데 사용됩니다.
- **머신 러닝**: 특정 피처(특징)가 주어졌을 때 다른 피처의 불확실성을 측정하여, 피처 선택 및 모델링 과정에서 중요한 역할을 합니다.
- **정보 이론**: 데이터 압축, 전송, 암호화 과정에서 정보의 효율성을 분석할 때 활용됩니다.

## 4. **조건부 엔트로피 계산의 예**

예를 들어, 두 이산 확률 변수 $X$와 $Y$가 각각 두 개의 값만을 가질 수 있다고 가정해보겠습니다. 이때 결합 확률 분포가 다음과 같이 주어졌다고 합시다:

$$
P(X, Y) = \begin{pmatrix} 
0.1 & 0.2 \\
0.3 & 0.4 
\end{pmatrix}
$$

이 경우 $Y$가 주어졌을 때의 조건부 엔트로피 $H(X|Y)$는 다음과 같이 계산됩니다:

$$
H(X|Y) = - \sum_{y \in \{y_1, y_2\}} P(Y=y) \sum_{x \in \{x_1, x_2\}} P(X=x|Y=y) \log P(X=x|Y=y)
$$

이를 계산하면, 주어진 $Y$의 정보에 따라 $X$의 불확실성이 얼마나 줄어드는지에 대한 값을 얻을 수 있습니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

# 운동량 방법 (Momentum Method)

**운동량 방법**(Momentum Method)은 경사 하강법(Gradient Descent)의 수렴 속도를 개선하기 위해 도입된 기법입니다. 이 방법은 최적화 과정에서 발생할 수 있는 진동을 줄이고, 더 빠르게 최적해에 접근하도록 도와줍니다. 특히, 고차원 공간에서의 최적화 문제에서 운동량 방법은 경사 하강법의 효율성을 크게 향상시킬 수 있습니다.

## 1. 기본 아이디어

운동량 방법은 물리학에서의 운동량 개념을 차용한 것으로, 이전 단계에서의 기울기(gradient)를 일정 비율로 반영하여 현재 기울기에 더합니다. 이를 통해 기울기의 변화 방향을 누적하여 보다 안정적이고 빠른 수렴을 유도합니다. 경사 하강법이 새로운 위치로 이동할 때, 운동량을 추가하면 현재의 움직임에 '관성'을 부여하게 되어, 이전의 기울기를 반영한 방향으로 가속화할 수 있습니다.

## 2. 수식 설명

일반적인 경사 하강법은 다음과 같이 업데이트됩니다:

$$
\theta_{t+1} = \theta_t - \eta \nabla_{\theta} J(\theta_t)
$$

여기서:
- $\theta_t$는 $t$번째 반복에서의 파라미터입니다.
- $\eta$는 학습률(learning rate)입니다.
- $\nabla_{\theta} J(\theta_t)$는 $\theta_t$에서의 비용 함수 $J(\theta)$에 대한 기울기입니다.

운동량 방법은 위 식에 운동량 항을 추가한 다음과 같은 형태로 업데이트됩니다:

$$
v_{t+1} = \beta v_t + (1 - \beta)\nabla_{\theta} J(\theta_t)
$$

$$
\theta_{t+1} = \theta_t - \eta v_{t+1}
$$

여기서:
- $v_t$는 $t$번째 반복에서의 속도(velocity) 벡터로, 이전 기울기의 영향을 누적합니다.
- $\beta$는 운동량 계수로, 이전 기울기를 반영하는 정도를 조절하는 하이퍼파라미터입니다. 보통 $\beta$는 0.9 정도로 설정됩니다.

## 3. 운동량의 효과

운동량 방법은 다음과 같은 장점이 있습니다:

- **진동 감소**: 경사 하강법의 반복 과정에서 발생할 수 있는 진동을 줄여줍니다. 특히 경사가 가파른 방향으로의 급격한 이동을 완화할 수 있습니다.
- **수렴 속도 증가**: 최적화 경로의 "관성"을 활용하여 평탄한 지역에서 더 빠르게 수렴할 수 있습니다.
- **최적해 탈출**: 국소 최적해(local minimum)에 갇힐 가능성을 줄여줍니다. 운동량이 기울기만으로는 탈출하기 어려운 지역을 빠져나가게 도와줍니다.

## 4. 네스테로프 가속 경사법 (Nesterov Accelerated Gradient)

운동량 방법의 한 가지 개선된 버전으로, **네스테로프 가속 경사법**(Nesterov Accelerated Gradient, NAG)이 있습니다. NAG는 현재 위치가 아니라 '예측된' 위치에서 기울기를 계산하는 방식으로, 다음과 같이 업데이트합니다:

$$
v_{t+1} = \beta v_t + (1 - \beta)\nabla_{\theta} J(\theta_t - \eta \beta v_t)
$$

$$
\theta_{t+1} = \theta_t - \eta v_{t+1}
$$

이 방법은 더욱 정밀하게 운동량을 반영하여 수렴 속도를 높이고 진동을 더욱 줄일 수 있습니다.

## 5. 운동량 방법의 적용

운동량 방법은 딥러닝과 같은 복잡한 최적화 문제에서 자주 사용됩니다. 예를 들어, 신경망을 훈련시키는 과정에서 일반적인 경사 하강법보다 훨씬 빠른 수렴을 이끌어낼 수 있습니다. 또한 Adam, RMSProp과 같은 더 발전된 최적화 알고리즘에도 운동량 개념이 포함되어 있습니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.

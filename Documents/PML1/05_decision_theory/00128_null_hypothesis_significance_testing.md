# 귀무가설 유의도 검정 (NHST: Null Hypothesis Significance Testing)

## 개요

귀무가설 유의도 검정(NHST: Null Hypothesis Significance Testing)은 통계적 가설 검정에서 가장 널리 사용되는 방법 중 하나로, 주어진 데이터가 귀무가설과 얼마나 일치하는지를 평가하는 데 사용됩니다. 이 방법은 데이터를 통해 가설을 검증하고, 그 결과를 바탕으로 결정을 내리는 과정에서 중요한 역할을 합니다.

## 기본 개념

### 1. 귀무가설 (Null Hypothesis, \( H_0 \))

귀무가설은 일반적으로 "차이가 없다" 또는 "효과가 없다"는 가정을 의미합니다. 이는 검정에서 기각하고자 하는 가설입니다. 예를 들어, 두 그룹의 평균이 같다는 가정이 있을 수 있습니다.

$$
H_0: \mu_1 = \mu_2
$$

### 2. 대립가설 (Alternative Hypothesis, \( H_1 \))

대립가설은 귀무가설에 반대되는 가설로, 연구자가 입증하고자 하는 가설입니다. 예를 들어, 두 그룹의 평균이 다르다는 가정이 있을 수 있습니다.

$$
H_1: \mu_1 \neq \mu_2
$$

### 3. 유의수준 (Significance Level, \( \alpha \))

유의수준 \( \alpha \)는 귀무가설이 참일 때, 이를 기각할 확률로 정의됩니다. 일반적으로 0.05 또는 0.01과 같은 값으로 설정됩니다. \( \alpha = 0.05 \)는 5%의 확률로 귀무가설을 잘못 기각할 수 있다는 것을 의미합니다.

### 4. p-값 (p-value)

p-값은 주어진 데이터가 귀무가설을 얼마나 지지하는지를 나타내는 지표로, 귀무가설이 참일 때 현재 데이터가 관측될 확률을 의미합니다. p-값이 유의수준 \( \alpha \)보다 작으면, 귀무가설을 기각하게 됩니다.

$$
\text{p-value} = P(\text{observed data} \mid H_0)
$$

### 5. 검정 통계량 (Test Statistic)

검정 통계량은 데이터에서 계산된 값으로, 이 값이 귀무가설 하에서 어떤 분포를 따르는지를 기반으로 합니다. 예를 들어, 평균 차이를 검정하기 위해 t-분포를 따르는 t-검정 통계량을 사용할 수 있습니다.

$$
t = \frac{\bar{X_1} - \bar{X_2}}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
$$

여기서 \( \bar{X_1}, \bar{X_2} \)는 각각 두 그룹의 표본 평균, \( s_p \)는 두 그룹의 결합 표준 편차, \( n_1, n_2 \)는 표본 크기입니다.

## NHST의 절차

1. **귀무가설과 대립가설 설정**: 분석하려는 문제에 따라 \( H_0 \)와 \( H_1 \)를 설정합니다.
2. **유의수준 설정**: 일반적으로 \( \alpha \)를 0.05 또는 0.01로 설정합니다.
3. **데이터 수집 및 검정 통계량 계산**: 데이터를 기반으로 검정 통계량을 계산합니다.
4. **p-값 계산**: 관측된 데이터에 기반하여 p-값을 계산합니다.
5. **결론 도출**: p-값이 유의수준보다 작으면 귀무가설을 기각하고, 그렇지 않으면 귀무가설을 기각하지 않습니다.

## NHST의 장점과 한계

### 장점

- **단순하고 직관적**: NHST는 간단한 규칙을 기반으로 하여 통계적 가설 검정을 직관적으로 수행할 수 있습니다.
- **넓은 적용 범위**: 다양한 분야와 다양한 유형의 데이터에 적용 가능합니다.

### 한계

- **의존적 해석**: p-값은 데이터가 귀무가설을 지지하는 정도만을 나타내며, 대립가설의 참 여부에 대한 정보를 직접 제공하지 않습니다.
- **유의수준의 임의성**: 유의수준 \( \alpha \)는 임의적으로 선택되며, 동일한 데이터라도 설정한 \( \alpha \) 값에 따라 결론이 달라질 수 있습니다.
- **효과 크기 무시**: p-값은 효과의 크기를 반영하지 않으므로, 통계적으로 유의한 결과라도 실제 효과가 작을 수 있습니다.

## 참고 문헌

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Murphy, K. P. (2022). *Probabilistic Machine Learning: An Introduction*. MIT Press.
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press.
